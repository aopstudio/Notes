# 一些简称
* CPI：指令时钟周期
* RTT：往返时延
* MST：最小生成树
* MDR：主存数据寄存器
* MAR：地址寄存器
* PCB :进程管理块。页表、页目录表的起始地址存放在PCB(进程控制块)中
* MTTR：故障发生后平均修复时间（Mean Time To Repair）
* MTTF：平均无故障工作时间（Mean Time To Failure）
   * 可用性=MTTF/(MTTF+MTTR)
* MTBF：系统两次故障发生时间之间的时间段的平均值(Mean Time Between Failure)
   * MTBF=MTTR+MTTF
* AFR：平均故障率
* DRAM：动态随机存取存储器
* SRAM：静态随机存取存储器
* EPC：异常程序计数器
* PCB：进程控制块
# 数据结构

## 逻辑结构和存储结构
**数据的逻辑结构独立于存储结构；数据的存储结构由逻辑结构决定，不能独立于逻辑结构**

不同的数据结构，逻辑结构和物理结构可以都相同，但数据的运算不一致。**数据的运算**也是数据结构的一个重要方面。如二叉树和二叉排序树。

链式存储设计时，不同节点的存储空间可以不连续，但**结点内**的存储单元地址必须连续
### 如何判断某种结构是逻辑结构还是存储结构或数据结构？
当一个结构，如数组、链表、树、图，在逻辑结构中只有一种定义，而在物理结构中却有两种选择，那么这个结构就属于逻辑结构；

相反，当此结构在原有基础上加上了某种限定，使得其在物理结构中只有一种定义，那么这个结构就属于物理（存储）结构；

举例1：栈属于什么结构？

分析：栈在逻辑结构中只能属于线性结构，而在物理结构中它可以使用顺序存储（数组），也可以使用链式存储（链表），所以说栈是一种逻辑结构。

举例2：线索二叉树属于什么结构？

分析：首先，可以得到二叉树是一种数据结构，但是线索二叉树是加上线索后的链表结构（不能用顺序存储），也就是说，它是计算机内部的只有一种存储结构，所以是物理结构。

## 时间复杂度
相同规模n下，复杂度为O(n)的算法在时间上必然优于复杂度为$O(2^n)$的算法

# 线性表
线性表的顺序存储结构是一种随机存取的存储结构

# 栈
n个不同元素进栈，出栈元素不同排列的个数是$\frac{1}{n+1}C^n_{2n}$

# 队列
最适合用作链式队列的链表是带队首指针和队尾指针的非循环单链表（如果循环，则添加完数据后还要修改为循环的）

单链表实现队列，队头设在链表的链头位置，因为队头要出（删除）元素，而链表的链头方便删除。如果队头设在队尾，则不管是否有尾指针，删除元素都要遍历队列

# 树
哈夫曼树不一定是二叉树，也可能存在度为m>2的哈夫曼树，只存在度为m和0的节点。哈夫曼编码其实不只是针对二进制，可以说任何进制都能使用哈夫曼编码（详见信息与编码相关书籍）。但是在计算机领域由于使用二进制，在数据结构上只介绍了二进制的哈夫曼编码，构造出来的哈夫曼树是度为二的树。

树、森林、二叉树遍历对应的关系
树      |森林    |二叉树
-------|------  |-----
先根遍历|先序遍历|先序遍历
后根遍历|中序遍历|中序遍历

若二叉树中，m是n的祖先，则使用**后序遍历**可以找到从m到n的路径

先序序列（或中序序列）为a,b,c,d的不同二叉树个数，相当于入栈顺序为a,b,c,d，求出栈排列的个数：$\frac{1}{n+1}C^n_{2n}$

二叉中序线索树中，X有左子节点且不为根，则X的前驱为**X的左子树中最右节点**

后续线索二叉树找后继节点需要知道结点双亲（线序线索二叉树找前驱也是），因此后续现所属的遍历仍需要栈的支持
# 图

极大连通子图：包含连通子图中所有的边
极小连通子图：只有连通图有极小连通子图，是保持图连通，又要使边数最小的子图。连通图顶点集确定的生成树是该连通图的极小连通子图，不唯一

若一个图有n个顶点，且有大于n-1条边，则该图一定有环

图的邻接矩阵表示唯一，邻接表表示不唯一（边的次序可以不同）

若邻接表中有奇数个边表结点，则图为有向图

图的广度优先搜索，空间复杂度为为O(|V|)。采用邻接表，时间复杂度为O(|V|+|E|)。采用邻接矩阵，时间复杂度为O(|V|^2^)
图的深度优先搜索，空间复杂度为为O(|V|)。采用邻接表，时间复杂度为O(|V|+|E|)。采用邻接矩阵，时间复杂度为O(|V|^2^)

## 最小生成树算法
Prim算法：先取顶点。时间复杂度：O(|V|^2^)。适用于边稠密的图
Kruskal算法：先取边。时间复杂度：O(|E|log|E|)。适用于边稀疏而顶点较多的图

## 最短路径算法
### Dijkstra算法
时间复杂度O(|V|^2^)

不适用于于边上带有负权值的情况
### Floyd算法
时间复杂度O(|V|^3^)

适用于于边上带有负权值的情况
## 关键路径
AOV网无权值，AOE网有权值

深度优先遍历、拓扑排序可以判断图是否有环。求关键路径本身无法判断有环，但求关键路径的第一步-拓扑排序能判断

拓扑排序唯一不能唯一确定该图，例子：
```dot {engine="circo"}
digraph g{
   V1->V2->V3->V4
   V1->V3->V4
   V2->V4
}
```
```dot {engine="circo"}
digraph g{
   V1->V2->V3->V4
}
```
## 排序
### 简单插入排序
在元素有序时效率可达O(n)

可能出现在最后一趟开始之前，所有元素都不在最终位置上

稳定

## 冒泡排序
每趟排序都会将一个元素放置到最终的位置上

稳定

## 快速排序
如果每次都取第一个元素为枢轴，那么当要排序的表基本有序或基本逆序时，效率最差，时间复杂度为O(n^2^)

快速排序平均时间复杂度为$O(n\log_2n)$，是所有内部排序算法中平均性能最优的算法

不稳定

快速排序是递归的，需要辅助栈，栈的平均大小（空间复杂度）为$O(\log_2n)$

## 基数排序
假设对n个d位r进制数排序，总共需要d趟分配和收集，一趟分配需要O(n)，一趟收集需要O(r)，所以技术排序的时间复杂度为O(d(n+r))。 与序列的初始状态无关

## B树
### 为什么要用B树？   
二叉树和B树查找的时间复杂度相同，均为O(logN)。但二叉树查找时需要频繁切换节点，不同节点的读取会导致磁盘IO操作（最坏情况是读取树的高度次），效率低下。为了减少磁盘IO的次数，就必须降低树的深度，将“瘦高”的树变得“矮胖”。
### 和二叉树的区别
二叉树以2为最大基准向下延伸，而B树则没有标准，所以它可以变得矮矮胖胖的。
### B树的性质
B 树又叫平衡多路查找树

**阶的含义**：描述一颗B树时需要指定它的阶数，阶数表示了一个结点最多有多少个孩子结点，一般用字母M表示阶数

**根节点子节点个数最小值限制**：根结点至少有两个子节点

**除根节点以外的非叶子节点的子节点个数最小值限制**：除根节点和叶节点外，其余所有节点至少有m/2棵子树（向上取整）

**所有的叶子结点都位于同一层**
### B树根节点分裂
根节点在没有子树时最多包含M-1个关键字，再加入时需要分裂出两个子树
## 堆
堆具有以下的特点：
1）完全二叉树；
2）heap中存储的值是偏序；

小根堆: 父节点的值小于或等于子节点的值；
大根堆: 父节点的值大于或等于子节点的值；

### 构建大根堆
1.从最后一个非叶子节点为父节点的子树出发，从右往左，从下往上进行调整操作（怎么调整下面讲）。这里需注意的是：

a.是以该非叶子节点为父节点的子树，即该父节点以下的所有部分都进行调整操作。

b.由于是从右往左从下往上，则某一步进行调整时在调整它之前的那些子树已经是堆有序了，即走到某个非叶子节点时，它的子树已经是堆有序了（因为是从下往上）

2.即调整函数 :

a.如果该节点比它的两个孩子节点都大，则该节点不用调整了，因为它的孩子节点也是堆有序 （上面b已说明）

b.如果该节点比它的两个子节点中的较大节点小，即array[i]< max(array[2i],array[2i+1]），将array[i]赋给temp，以后每次都跟temp比较，好多博客说的是交换两个值，其实程序里是直接比较temp。将max(array[2i],array[2i+1])赋给array[i]。接着从max(array[2i],array[2i+1]) 对应的那个节点出发，继续进行该操作，直到该节点到达了n。当然每次判断边界条件为左子树的索引小于n，则右子树才有值

## 希尔排序
首先它把较大的数据集合分割成若干个小组（逻辑上分组），然后对每一个小组分别进行插入排序，此时，插入排序所作用的数据量比较小（每一个小组），插入的效率比较高

![](http://p1.pstatp.com/large/pgc-image/1523763390411731c4d486d)

每个分组进行插入排序后，各个分组就变成了有序的了（整体不一定有序）
![](http://p9.pstatp.com/large/pgc-image/1523763390605f1acc654c8)

然后缩小增量为上个增量的一半:2，继续划分分组，此时，每个分组元素个数多了，但是，数组变的部分有序了，插入排序效率同样比高
![](http://p3.pstatp.com/large/pgc-image/15237633906876d1db94cf9)

同理对每个分组进行排序（插入排序），使其每个分组各自有序

![](http://p9.pstatp.com/large/pgc-image/1523763390761f7f32df528)

最后设置增量为上一个增量的一半：1，则整个数组被分为一组，此时，整个数组已经接近有序了，插入排序效率高

![](http://p3.pstatp.com/large/pgc-image/152376339087072702782c5)

## 三元组表、十字链表
**都用于稀疏矩阵的存储**

三元组表：存储非零元素的行标、列标和元素值的线性表

十字链表：除了存放三元组表的三个元素，还要存放邻接矩阵中横向的下一个非零节点的地址（即出边指向的结点）和邻接矩阵中纵向的下一个非零节点的地址（即入边出发的结点），即每行为一个链表，每列为一个链表

## 图的边和顶点度数的关系、
有向图和无向图，边的两倍都是顶点度数的总和

## 图的边和顶点数的关系
记边数为e，顶点数为n

1、若G是无向图，则0≤e≤n(n-1)/2。

恰有n(n-1)/2条边的无向图称无向完全图(Undireet-ed Complete Graph)。

2、若G是有向图，则0≤e≤n(n-1)。

恰有n(n-1)条边的有向图称为有向完全图(Directed Complete Graph)。

## 折半查找判定树
实际上是一棵二叉排序树，它的中序序列是一个有序序列

构建时，取中间值时要么全部向上取整，要么全部向下取整。不能出现有的区间向上取整，有的区间向下取整的情况

## 树的遍历
### 中序遍历
```c
void InOrder(BiTree T) {
    if(T!=null){
        InOrder(T->lchild);     //递归遍历左子树
        visit(T);   //访问根结点
        InOrder(T->rchild);     //递归遍历右子树
    }
}
```
先序、后序类似可推，将visit的位置改变即可

## 最小生成树（MST）
最小生成树唯一的充分条件：任意一个环中所包含的边的权值均不相同 
## 和顺序存储相比，链式存储算法时间效率
插入排序、选择排序、冒泡排序不变，都是$O(n^2)$

希尔排序和堆排序都利用了顺序存储的随机访问特性，时间复杂度会增加
## C语言动态数组定义并赋初值0
假设要定义一个含有n个元素的数组A，并给所有元素赋初值位0，代码如下
```c
int *A;
A=(int *)malloc(sizeof(int)*n); 
memset(A,0,sizeof(int)*n);
```
## 排序
### 插入排序
#### 1. 直接插入排序
   * 特点：待排序数组一部分是有序的，另一部分是无序的。
   * 时间效率：当数组元素有序时，$f(n)=O(n)$。一般情况下，$f(n)=O(n^2)$。
  
  * 稳定
#### 2. 折半插入排序
  * 主要针对直接插入排序的定位算法进行优化。定位更快，插入不变。
  * 时间效率：$f(n)=O(n^2)$。

  * 稳定
#### 3. 希尔排序
   * 设置步长d将表分块，在不同块中使用直接插入排序，逐步缩小d指到1。
   * 不稳定的算法
   * 仅适用于顺序存储的线性表
   * 时间效率：较佳情况下$f(n)=O(n^{1.3})$，最坏情况$f(n)=O(n^2)$。

   * 不稳定
### 交换排序
#### 1. 冒泡排序
   * 时间效率：当数组元素有序时，$f(n)=O(n)$。一般情况下$f(n)=O(n^2)$。
   * 稳定
#### 2. 快速排序
   * 通过一趟排序将排序表划分为左右两部分，使得左边所有元素小于右边所有元素。 
   * 不稳定

   选择一个枢轴元素，再完成一趟划分之后，将待排序序列分割成两部分。左侧元素的关键字小于等于枢轴元素的关键字；右侧元素的关键字大于等于，枢轴元素的关键字。再分别对两部分元素重复上述过程，直到整个序列有序

   
   ```c
   void QuickSort(ElemType A[],int low,int high){
      if(low<high){
         int pivotpos=Partition(A,low,high);
         QuickSort(A,low,pivotpos-1);
         QuickSort(A,pivotpos+1,high);
      }
   }
   int Partition(ElemType A[],int low,int high){
      Elemtype pivot=A[low];
      while(low<high){
         while(low<high&&A[high]>=pivot) --high;
         A[low]=A[high];
         while(low<high&&A[low]<=pivot) ++low;
         A[high]=A[low];
      }
      A[low]=pivot;
      return low;
   }
   ```
   从前往后查看元素，标记为i；从后往前查看元素，标记为j。  
   先从j开始，如果a[j]>a[i],则j--；否则swap（a[i],a[j]）,并将主动权给到i。  
   从i开始后，如果a[j]>a[i],则i++；否则swap（a[i],a[j]）,并将主动权还给j。  
   最后直到满足一轮排序的要求。  

   * 效率：当数组元素有序时，$f(n)=O(n^2)$。一般情况下，$f(n)=O(n*log_2n)$
   * 在快排中，不会产生有序序列，但每趟排序会将一个元素放到最终位置上。

### 选择排序
#### 1. 简单选择排序
   * 每一趟选一个最小的放到最前面

   * 不稳定
#### 2. 堆排序
   * 堆的定义：n个关键字序列$L[1...n]$称为堆，当且仅当该序列满足其中一条：  
     1) $L(i)\leqslant L(2i)$且$L(i)\leqslant L(2i+1)$
     2) $L(i)\geqslant L(2i)$且$L(i)\geqslant L(2i+1)$
  
   * 小根堆：最小元素存放在根结点中，对任意非根结点，它的值$\geqslant$其双亲结点的值。
   * 堆排序：一种树形排序方法，将$L[1...n]$看作一棵完全二叉树的顺序存储结构。
   * 堆的构造：先按初始序列建造成完全二叉树的形式，再进行调整，**反复调整**。
    * 堆的删除：只能删除堆顶元素，删除前先将最后一个元素和堆顶元素交换，再向下调整。
    * 堆的插入：插入在堆的末端，再向上调整。
    * 空间复杂度：$O(1)$
    * 时间复杂度：建堆时间$O(n)$，调整时间$O(h)$。排序时间始终是$O(nlog_2n)$。

   * 不稳定
### 归并排序
  * 归并：将两个或两个以上的有序表组合成一个新的有序表。
  * 空间复杂度：$O(n)$
  * 时间复杂度：每趟归并$O(n)$，归并次数$log_2n$。最终时间$O(nlog_2n)$。

   * 稳定

优点：
* 归并排序的效率达到了巅峰：时间复杂度为O(nlogn)，这是基于比较的排序算法所能达到的最高境界
* 归并排序是一种稳定的算法（即在排序过程中大小相同的元素能够保持排序前的顺序，3212升序排序结果是1223，排序前后两个2的顺序不变），这一点在某些场景下至关重要
* 归并排序是最常用的外部排序方法（当待排序的记录放在外存上，内存装不下全部数据时，归并排序仍然适用，当然归并排序同样适用于内部排序）

### 基数排序
  * 多关键字排序思想。对单关键字采用“分配”和“收集”两种操作。
  * r是辅助存储空间，即r个队列。n是n个元素。
  * 空间复杂度：$O(r)$
  * 时间复杂度：$O(d(n+r))$

## 已知先序序列，有多少种不同的二叉树；n个元素进栈出栈序列的个数
先序序列和中序序列的关系相当于以先序序列为入栈次序，以中序序列为出栈次序。因为先序序列和中序序列能唯一确定一棵二叉树，所以已知先序序列求二叉树个数即求以先序序列为入栈次序，则出栈序列的个数为多少。

对于n个不同元素进栈，出栈序列为$\frac{1}{n+1}C^n_{2n}$个

# 计算机组成原理
## Amdahl定律
改进后的执行时间=受改进影响的执行时间/改进量+不受影响的执行时间
## 磁盘的最小读写单位
* 字节：从应用程序包括用户界面的角度来看，存取信息的最小单位是

* 扇区：从磁盘的物理结构来看存取信息的最小单位，一般一个扇区是512字节

* 簇：从操作系统对硬盘的存取管理来看，是存取信息的最小单位，即最小分配单位。

## 冒险
### 结构冒险
如果一条指令需要的硬件部件还在为之前的指令工作，而无法为这条指令提供服务，那就导致了结构冒险
### 数据冒险
因无法提供指令执行所需数据而导致指令不能在预定的时钟周期内执行的情况

使用旁路或流水线阻塞

### 控制冒险
如果现在要执行哪条指令，是由之前指令的运行结果决定，而现在那条之前指令的结果还没产生，就导致了控制冒险

使用分支预测（假设某种情况发生，直接执行该种情况）或延迟决定（先干别的事）

## DMA
DMA是指外部设备不通过CPU而直接与系统内存交换数据的接口技术


每类设备都配置一个设备驱动程序，设备驱动程序向上层用户提供一组标准接口，负责实现对设备发出各种具体操作指令，用户程序不能直接和DMA打交道。DMA的数据传送过程分为预处理、数据传送和后处理三个阶段

**预处理阶段**：由CPU完成必要的准备工作，数据传送前由DMA控制器请求总线使用权

**数据传送阶段**：DMA控制器直接控制总线完成

**传送结束后**：DMA控制器向CPU发送中断请求，CPU执行中断服务程序做DMA结束处理

CPU和DMA控制器同时要求使用存储器总线时，DMA的优先级更高，因为DMA请求如果得不到及时响应，I/O传输数据可能丢失
###  DMA传输过程
主机向内存写入DMA命令块，向DMA控制器写入该命令块的地址，启动IO设备。然后，CPU继续其他工作，DMA控制器则继续下去直接操作内存总线，将地址放到总线上开始传输。当整个传输完成后，DMA控制器中断CPU
## 通道
通道是一独立于CPU专管输入输出的处理器，它控制外存与内存之间的信息交换
### DMA和通道的区别
在DMA方式中，数据的传送方向、存放数据的内存始址以及传送的数据块长度等都由CPU控制，而在通道方式中，这些都由通道来进行控制。另外，DMA方式每台设备至少需要一个DMA控制器，一个通道控制器可以控制多台设备。

## 主存地址组成
主存标记 |组号 |块内地址

组号位数由组的个数决定。假设Cache总共64行，采用4路组相联。一个组含有几块称为几路组相联。则组数=64/4=16。2^4^=16，因此需要4位组号

块内地址位数由主存块大小决定。设主存块大小为64B。2^6^=64。因此需要6位块内地址

除去组号和块内地址，剩下的位数即为主存标记


## IEEE 754
![](https://www.fleaplc.it/images/Articoli/FloatToDW/Immagini/IEEE753_32Single_Wiki.jpg)
单精度：
一位符号位，8位阶码，23位尾数
阶码是移码，偏置量为127。计算时取出阶码要减127才是阶数
尾数是原码

阶码全1，尾数全0表示无穷大
## 逻辑移位和算术移位
逻辑移位：左移和右移空位都补0，并且所有数字参与移动

算术移位：符号位不参与移动，右移空位补符号位，左移空位补0

## 周转时间和等待时间
周转时间=作业完成时间-进入作业队列时间

等待时间=作业开始时间-进入作业队列时间

## 物理地址和逻辑地址相关
物理地址位数=实页号位数+页内地址位数



## Cache地址结构
### 直接映射
地址结构：

主存字块标记 | Cache字块标记 | 字块内地址
### 全相联映射
地址结构：

主存子块标记 | 字块内地址
### 组相联映射
地址结构：

主存字块标记 | 组地址 | 字块内地址


## Cache地址做法
1. 根据主存大小求出主存地址位数
2. 根据块大小求出块内地址位数

全相联：
3. 标记位位数=主存地址位数-块内地址位数

直接相联：
3. 根据cache含有的块数求出Cache行号（索引）位数
4. 标记位位数=主存地址位数-Cache行号位数-块内地址位数

组相联：
3. 根据cache含有的组的数量（不要和每组多少块搞混）求出组地址位数
4. 标记位位数=主存地址位数-组地址位数-块内地址位数
## Cache标记阵列包含字段
有效位 **必须有**，1位

标记位 **必须有**，和地址结构中的主存字块标记位数相同，=地址位数-Cache字块标记位数（根据Cache中包含多少行得出）-字块内地址位数

一致性维护位（脏位） 如果使用回写，则需要1位；如果使用全写，则不需要

替换算法控制位：题目中提到替换算法则需要，没提到则不需要
## Cache写策略
### 1. 全写法（写直通法）
当CPU对Cache写命中时，必须把数据同时写入Cache和主存。当某一块需要替换时，不必把这一块写回主存，将新调入的块直接覆盖即可。这种方法实现简单，能随时保持主存数据的正确性。缺点是增加了访存次数，降低了Cache的效率
### 2. 写回法
当CPU对Cache写命中时，只修改Cache的内容，而不立即写入主存，只有当此块被换出时才写回主存。这种方法减少了方寸次数，但存在不一致的隐患
## 页式虚拟存储器
![](https://img-blog.csdnimg.cn/20190902214005168.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MjkxOTM0,size_16,color_FFFFFF,t_70)
页：进程中的块（进程被分成许多大小相同的块）
页框：内存中的块（内存被分成许多大小相同的块）
页的大小=页框大小
页表：存储进程中的每一页所对应的页框的位置（进程中的每一块对应在内存中的位置）

页表项： 页号（标记） | 页框号（虚页号）

页表项地址：指向页表中的元素（即页表项）

逻辑地址（页号，偏移量） （逻辑地址就是虚拟地址）
物理地址（页框号，偏移量）
###  TLB（快表）
![](https://img-blog.csdnimg.cn/20190902214637696.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MjkxOTM0,size_16,color_FFFFFF,t_70)
**放在主存中的页表叫做慢表**

TLB采用全相联映射，采用SRAM实现

TLB是页表的子集，相当于页表的cache。TLB命中，页表一定命中；页表命中，TLB不一定命中

TLB每行都有有效位，有效位为1才能用

TLB命中，访问某个逻辑地址只需要一次访问内存；TLB没有命中，访问某个逻辑地址需要两次访问内存
###  虚拟地址结构
虚页号 | 页内地址

虚页号又可分为：页目录号 | 页号

### 单级页表的问题
页表必须连续存放，当页表很大时，需要占用很多个连续的页框
解决方案：多级页表

没有必要让整个页表中指向的所有页常驻内存，因为进程在一段时间内可能只需要访问几个特定的页面
解决方案：在需要访问的时候才把页面调入内存，为此在页表项中增加**标志位**表示页表项对应的页是否在内存中
### 两级页表
把页表项分组，变成多个小页表，存在内存不同的位置

对不同的小页表也要建立一张表用来检索，称为**页目录表**

地址结构：
一级页号+两级页号+页内地址

需要多一次访存

#### 多级页表
如果采用多级页表，那么各级页表的大小不能超过一个页面所能存储的最多页表项的数量。
原因：本来多级页表就是为了解决当页表很大时，需要占用很多个连续的页框的问题。如果一个页表超过了一个页框的空间，就失去了采用多级页表的意义

例题：
字节编址，40位逻辑地址，页面大小4KB，页表项大小4B，需要采用（3）级页表

解：页内地址12位
页号位数=40-12=28位
一页最多能存2^10^个页表项。所以每级页表的页表项地址的最大位数为10

28=10+10+8
所以采用3级页表
## 段式虚拟存储器
![](https://img-blog.csdnimg.cn/20190902214202826.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MjkxOTM0,size_16,color_FFFFFF,t_70)
段的大小不固定

段表寄存器：存储了段表起始地址和段表长度（段表项个数）

段表项地址：指向段表中的元素（即段表项）
### 虚拟地址
段号+段内地址

段号决定了每个进程最多分多少个段
段内地址决定了每个段的最大长度是多少

物理地址按段为单位分配

### 段表
段表项包含：标志位、段号、段起点（段基址）和段长度

每个段表项的长度相同

问题求段地址，答案可能是越界
## 段页式虚拟存储器
把程序按逻辑分段，每段再分页，主存空间页划分为大小相等的页
程序对主存的调入调出仍以页为单位

每个程序对应一个段表，每段对应一个页表

虚拟地址：段号+段内页号+页内地址

需要检查页号是否越界（因为各个段所包含的页数不同）

需要三次访存
### 段表
段表项存放：页表长度+页表存放块号
### 页表
页表项存放：页号+内存块号

## 分页和分段比较
页对用户是不可见的；分段对用户是可见的，用户编程时需要给出段名

页的大小固定，段的大小不固定

分页的地址空间是一维的，只要给出一个记忆符即可表示一个地址；分段地址空间是二维的，既要给出段名，也要给出段内地址；段页式也是二维的

分段比分页更容易实现信息的共享和保护

程序正在运行时，由**操作系统**完成地址映射
## 请求分页
页表包含：
1. 标志位（状态位）：页面是否调入内存
2. 访问字段：记录最近访问几次，或上次访问时间，供置换算法使用
3. 修改位：页面调入内存后是否修改过
## 各种寄存器
### PDBR（页目录基址地址寄存器）
其存储页目录表物理内存基地址。进程切换时，PDBR的内容会变化；同一进程的线程切换时，PDBR的内容不会变化。每个进程的地址空间、页目录和PDBR的内容存在一一对应的关系。进程切换时，地址空间发生了变化，对应的页目录及其起始地址也相应变化，因此需要用进程切换后当前进程的页目录起始地址刷新PDBR。同一进程中的线程共享该进程的地址空间，其线程发生切换时，线程使用的页目录不变，因此PDBR的内容也不变。

### IR（指令寄存器）
用于存放当前从主存储器读出的正在执行的一条指令

### 移位寄存器
能在时钟信号的作用下使其中的数据依次左移或右移

### PC（程序计数器）
用于存放下一条指令所在单元的**地址**

## 各种标志位
各标志位含义：

* CF（进位标志） =1 算术操作最高位产生了进位或借位 =0 最高位无进位或借位 ；

* PF（奇偶标志） =1 数据最低8位中1的个数为偶数 =0 数据最低8位中1的个数为奇数；

* AF（辅助进位标志） =1 D3→D4位产生了进位或借位 =0 D3→D4位无进位或借位；

* ZF（零标志） =1 操作结果为0 =0 结果不为0；

* SF（符号标志） =1 结果最高位为1 =0 结果最高位为0；

* OF（溢出标志） =1 此次运算发生了溢出 =0 无溢出。SF
## CD-ROM
不采用随机存取方式

## 系统总线
### 数据总线
双向传输总线。数据总线上传输的不一定是单纯的数据，也有可能是指令代码或状态信息，甚至可以是控制信息。位数与机器字长、存储字长有关
### 地址总线
单向传输总线，用来指出数据总线上的源数据或目的数据所在的主存单元或I/O端口的地址。位数与存储单元的个数有关
### 控制总线
传输控制信息，包括CPU送出的控制命令和主存（或外设）返回CPU的反馈信号
## 寻址
### 立即寻址
所提供的操作数紧跟在操作码后面，与操作码一起放在指令代码段中，不需要到其他地址单元中去取。这种寻址方式速度**最快**

访存次数：0
### 寄存器寻址
在指令中指出需要使用的寄存器，操作数有效地址在寄存器中

访存次数：0
### 直接寻址
操作数在内存中，指令直接包含有操作数的有效地址 

访存次数：1
### 一次间接寻址
指令给出一个内存块的地址，该内存块中包含了操作数的有效地址，再去该地址取数

访存次数：2
### 基址寻址
CPU中基址寄存器BR的内容加上指令字中形式地址A。BR的内容由操作系统决定，在程序执行过程中BR的内容不可变，而形式地址是可变的。基址寻址方式适合解决动态定位的问题

访存次数：1
### 变址寻址
有效地址是将CPU中变址寄存器IX的内容加上指令字中有效地址A。其指令字的形式地址作为一个基准地址，内容不可变，而CPU中变址寄存器IX在程序执行过程中根据使用情况发生改变。这样的寻址方式非常适合于循环问题，适合按下标顺序访问一维数组元素，指令提供数组首地址，由变址寄存器来定位数据中的各元素

访存次数：1
### 相对寻址
以PC为基地址，以指令中的地址为偏移量确定有效地址

目标地址=（PC）+偏移量

访存次数：1

## 访问局部性
CPU访问中的局部性原理
主要两点：时间与空间

* 时间局部性：理解的关键点在于“访问的时间间隔”，比如for循环实现sum求和，sum就是这次访问了，下次还被访问，体现的就是时间局部性。
* 空间局部性：理解的关键点“存储的位置”，相邻的数据很可能被一同访问到。cache的基本原理就体现了这一点。
数组和链表通常具有很好的空间局部性

## 控制存储器（CM）
在CPU内，存储微指令，

## 流水线
分为
* 取指
* 译码/取数
* 执行
* 存储器读
* 写回

各个子系统通过数据总线连接形成的数据传送路径称为数据通路，包括程序计数器、算术逻辑运算部件、通用寄存器组、取指部件等，**不包括控制部件**
## DRAM芯片地址引脚和数据引脚计算
假设有一个4M*8位的芯片，则它的数据引脚数量为8，地址引脚数量为$\frac{\log_24M}{2}=11$，因为DRAM采用地址复用技术，地址线是原来的1/2

注意：问芯片的地址引脚和数据引脚只看单个芯片即可，不要被总容量干扰

## 突发传输、并行传输、串行传输、同步传输
突发传输是在一个总线周期中，可以传输多个存储地址连续的数据，即一次传输一个地址和一批地址连续的数据。

并行传输是指在传输中有多个数据位同时在设备之间进行的传输

串行传输是指数据的二进制代码在一条物理信道上以位为单位按时间顺序逐位传输的方式

同步传输是指传输过程由统一的时钟控制

## I/O接口相关
I/O接口中CPU可访问的寄存器称为I/O端口

状态端口和控制端口可以合用一个寄存器

采用统一编址时，CPU访存和访问I/O端口用的是一样的指令，所以访存指令可以访问I/O端口

采用独立编址方式时，I/O端口地址与存储器地址无关，但I/O端口地址和主存地址可能相同，因此需要设置专门的I/O指令来访问端口

## 程序员可见的寄存器
PC，通用寄存器

## MIPS指令体系
### R型指令
![](https://img-blog.csdnimg.cn/20210515163722774.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzU3NDQ2Mjg0,size_16,color_FFFFFF,t_70)
* OP：000000（R型指令固定为000000）
* func：决定指令的功能
* rs、rt：两个源操作数所在的寄存器号
* rd：目的操作数所在的寄存器号
* shamt：位移量，执行移位操作的时候指明需要移动的次数
![](https://img-blog.csdnimg.cn/20210515163810291.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzU3NDQ2Mjg0,size_16,color_FFFFFF,t_70)
### I型指令
![](https://img-blog.csdnimg.cn/20210515165800755.png)
* rs、rt：寄存器
* immediate：常量
![](https://img-blog.csdnimg.cn/20210515165747713.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzU3NDQ2Mjg0,size_16,color_FFFFFF,t_70)

不同的指令中，rs、rt、immediate的作用也不同

lw：rs表示存放内存基址的寄存器，immediate表示地址偏移量，rt表示取出数据后要存入的寄存器。运行时先从rs取出内存基址，加上immediate值，得到内存地址后从内存取值，取到的值存入rt
sw：rs表示存放内存基址的寄存器，immediate表示地址偏移量，rt表示将要存入内存的数据的来源寄存器。运行时先从rs取出内存基址，加上immediate值，得到内存地址，之后将rt的值存入内存中对应位置
beq，bne：rs，rt存放用来比较的值，若相等（不相等）则跳转到immediate指向的地址

### J型指令
![](https://img-blog.csdnimg.cn/20210515172043999.png)
![](https://img-blog.csdnimg.cn/2021051517212342.png)
## 流水线
### 吞吐率
单位时间内流水线所完成的任务数量，或输出结果的数量
$TP=\frac{n}{T_k}$
n是任务数，$T_k$是处理完n个任务所用的时间

k段流水线能在k+n-1个时钟周期内完成n个任务
$TP=\frac{n}{(k+n-1)\Delta t}$

### 加速比
完成同样一批任务，不使用流水线所用的时间与使用流水线所用的时间之比
$S=\frac{T_0}{T_k}$

### 时钟周期
非流水线时钟周期：每段数据通路的延迟加起来

流水线时钟周期：数据通路力最长的一段延迟

### 各个阶段
IF：取指阶段
ID：指令的移码或寄存器堆的读取阶段
EX：指令的执行阶段
MEM：数据存储器（内存）访问
WB：写回寄存器堆

### 不同类型指令所做的阶段不同
lw：所有阶段都有
sw：没有WB阶段（因为结果直接写回内存）
R型（add,sub,AND,OR,slt）：没有MEM阶段（因为计算结果只会存到寄存器）
分支（beq,bne,J型）：没有MEM和WB阶段（因为不需要从内存取值以及将结果写回寄存器）


# 操作系统
**并发**和**共享**是操作系统两个最基本的特征

用户可以通过**命令接口**和**系统调用**两种方式来使用计算机，系统调用也叫**广义指令**

系统调用只能通过用户程序间接使用

操作系统与用户通信接口通常不包括**缓存管理指令**，该指令对用户透明，用户感知不到

分时系统追求的目标是**比较快速响应用户**
## 系统调用过程
1. 传递系统调用参数
2. 执行陷入（trap）指令将用户态转化为内核态，并将返回地址压入堆栈以备后用
3. 执行相应的内核态服务程序
4. 返回用户态
## 中断
* 外部中断请求
* CPU内部异常

中断发生后，进入中断处理的程序属于操作系统程序

用户态到核心态的转换是由硬件完成的

只能在核心态下运行的指令是置时钟指令

处理外部中断时，关中断、保存PC的值、引出中断服务程序是由硬件自动（中断隐指令）完成的，通用寄存器的内容由操作系统保存

中断向量用于存放中断服务例行程序的入口地址，中断向量地址是该入口地址的存放地址
### 关中断
保护被中断进程现场时关中断，而在执行中断处理程序的时候则是开中断的

### 中断隐指令
中断隐指令并不存在于指令系统中，而是由硬件直接执行，其完成的操作如下所示
1. **关中断**。为了保护中断现场（即CPU主要寄存器中的内容）期间不被新的中断打断，必须关中断，从而保证被中断的程序在中断返回之后能继续正确地执行下去
2. **保存断点**。为了保证在中断服务程序执行完毕后能正确地返回到原来的程序，必须将原来程序的断点（即程序计数器（PC））的内容保存起来
3. **引出中断服务程序**。实质就是查找出中断服务程序的入口地址并传送给程序计数器（PC）。常用的查找方法是硬件向量法，通过硬件产生中断向量地址（中断类型号），而中断向量地址中存放着中断服务程序的入口地址

程序计数器PC由中断隐指令保存

### 内中断和外中断
#### 内中断
* 陷阱、陷入：有意为之的，如系统调用
* 故障：可能被故障处理程序恢复，如缺页中断
* 中止：不可恢复的致命错误

#### 外中断
* I/O中断请求
* 人工干预
##### 外部中断需要保存的
通用寄存器由操作系统保存


### 用户态和核心态
系统调用发生在用户态，被调用程序在核心态下执行

外部中断是用户态到核心态的“门”，也发生在用户态，在核心态完成中断过程

进程切换属于系统调用执行过程中的事件，只能发生在核心态

缺页发生后，在用户态发生缺页中断，然后进入核心态执行缺页中断服务程序
#### 不能在用户态执行的指令
关中断指令
### I/O软件的层次结构
从上到下依次为：

1. 用户层I/O软件
2. 设备独立性软件
3. 设备驱动程序
4. 中断处理程序
5. 硬件设备
### 用户级线程和内核级线程
内核级线程的调度由操作系统完成

多线程模型中用户级线程和内核级线程的连接方式分为多对一、一对一、多对多

用户级线程的切换可在用户空间完成，内核级线程的切换需要操作系统帮助进行调度，故**用户级线程的切换效率更高**

用户级线程的管理工作可以只在用户空间中进行，故可以在不支持内核级线程的操作系统上实现

## 进程和线程
在支持线程的系统中，线程是调度的基本单位

不管系统是否支持线程，进程都是分配资源的基本单位

在用户级线程中，有关线程管理的所有工作都由应用程序完成，无须内核的干预

同一线程可被不同进程调用，如系统动态DLL库中的系统线程，被不同的进程所调用，但还是相同的线程

设备分配不需要创建新进程。用户登录成功、启动程序执行需要创建新进程
### PCB
进程实体由程序段、相关数据段和PCB三部分组成。PCB是进程存在的唯一标志

PCB的组织方式有链接方式和索引方式两种

### 进程间通信方式
1. 共享存储
2. 消息传递
3. 管道
管道只能采用半双工通信
管道为空时，进程读管道阻塞，管道满时，进程写管道阻塞

操作系统通过进程控制块（PCB）对并发执行的进程进行控制和管理

### 进程数据存储位置
1. 正文段
即代码和赋值数据段
一般存放二进制代码和常量

2. 数据堆段
动态分配的存储区在数据堆段

3. 数据栈段
临时使用的变量在数据栈段

## 处理机调度
周转时间=作业完成时间-作业提交时间

带权周转时间=作业周转时间/作业实际运行时间

等待时间=等处理机状态的时间之和

响应时间：用户提交请求到系统首次产生响应所用的时间

进程处于临界区时也可以进行处理机调度（比如调用打印机）

### FCFS
FCFS最简单，是非抢占式的

进程按照请求CPU的顺序排序

上述例子解决图
![graph1](https://img-blog.csdn.net/20180121005129300?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllbWlueWFvMTIz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

表格
![sheet1](https://img-blog.csdn.net/20180121005206006?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllbWlueWFvMTIz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
### SJF
如果运行时间事先已知，可以每次挑选最短的任务以避免convoy effect(护航效应，即小进程等待大进程释放)

也是非抢占式的。

例子图
![graph2](https://img-blog.csdn.net/20180121005249291?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllbWlueWFvMTIz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
例子中A运行结束时间为3，这时只有B进程等待。所以A运行结束后直接运行B。B结束后时间点到9，CDE都在等待。这个时候就选择服务时间最少的E，然后是较少的C，最后是D。
以表格的形式展示：
![sheet2](https://img-blog.csdn.net/20180121005319025?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllbWlueWFvMTIz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

#### SJF的优点
可以证明**SJF的平均周转时间最短**
避免了护航效应（convoy effect）
#### SJF的缺点
难以得知下次CPU请求的长度，只能预测。一般通过数学期望 $t_{n+1}=at_{n}+(1-a)t_{n}$ 来确定

### SRTF
SRTF是抢占式的，有时也被称为抢占式的SJF

* 当前剩余运行时间最短的进程被挑出来
* 如果新到达进程的CPU Burst time比当前执行进程的要短，则抢占

例子图
![graph3](https://img-blog.csdn.net/20180121005401910?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllbWlueWFvMTIz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

1. A先运行至2，B到达等待。
2. A运行到3结束，B开始运行。
3. B开始运行，运行到4时，C进程到达，且C只需要4，此时B还需要5。所以先运行C，B继续等待。
4. C运行时间点到达6时，D到达，D需要5，进入等待，排在B后。
5. C运行结束，此时时间点是8，E到达，运行时间只要2，小于等待的BD，直接运行。
6. C运行结束，B开始运行。
7. B运行结束，D开始运行。

表格形式：
![sheet3](https://img-blog.csdn.net/20180121005423134?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllbWlueWFvMTIz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

### 高响应比优先调度算法
综合考虑任务长度和等待时间，满足短任务优先且不会发生饥饿现象

响应比=(等待时间+要求服务时间)/(要求服务时间)

1. 等待时间相同时，要求服务时间越短，响应比越高
2. 要求服务时间相同时，等待时间越长，响应比越高
3. 对于长作业，作业的响应比可以随等待时间的增加而提高

### 时间片轮转调度算法
遵循先来先服务的原则，但仅能运行一个时间片
先给定时间片的大小
* 如果在一个时间片内执行完就退出执行其他任务
* 如果在一个时间片内执行不完将该任务放到队尾

时间片过大变成FCFS，时间片过小，处理机在进程间过于频繁切换，开销增大

比SJF的平均周转时间长，但有更好的响应时间

### 多级反馈队列调度算法
时间片轮转算法和优先级调度算法的综合和发展

1. 设置多个就绪队列，为各个队列赋予不同的优先级，第1级最高，其余优先级逐次降低
2. 各个队列的时间片大小各不相同。优先级越高，时间片越小
3. 新进程进入内存后，先放到第1级队列末尾，按FCFS原则排队等待调度。轮到该进程执行时，如果它能在一个时间片内完成，便可撤离系统。如果在1个时间片结束时尚未完成，该进程转入第2级队列末尾，再按FCFS等待，如果在第2级队列时间片过后还未完成，转入第3级……
4. 仅当第1级队列为空时，调度程序才调度第2级队列中的进程运行。若处理及正在执行第i级队列中的某进程，这时又有新进程进入优先级较高的队列，则新进程将抢占正在运行进程的处理机

#### 多级反馈队列的优点
1. 终端型作业用户：短作业优先
2. 短批处理作业用户：周转时间较短
3. 长批处理作业用户：经过前面几个队列得到部分执行，不会长期得不到处理

## 进程同步
### 临界资源
一次仅允许一个进程使用的资源成为临界资源

在每个进程中，访问临界资源的那段代码称为**临界区**

可把临界资源的访问过程分成4个部分
1. 进入区
2. 临界区
3. 退出区
4. 剩余区

### 同步
同步亦称直接制约关系，是指为完成某种任务而建立的多个进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系

### 互斥
互斥也称间接制约关系。当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源

### 基本准则
为禁止两个进程同时进入临界区，同步机制应当遵循以下准则：
1. **空闲让进**：临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区
2. **忙则等待**：已有进程进入临界区时，其他试图进入临界区
3. **有限等待**：对请求访问的进程，应保证能在有限时间内进入临界区
4. **让权等待**：当进程不能进入临界区时，应立即释放处理器，防止进程忙等待
## 动态内存分配算法
最佳适应算法最容易产生内存碎片

## 大端和小端
32bit宽的16进制 0x12345678 在内存中的存放方式：

**在内存表示中，左边的是低地址，右边的是高地址**

大端： 高字节存储在低地址，低字节存储在高地址

内存地址|	0x4000|	0x4001|	0x4002|	0x4003
-------|---------|-------|-------|-------
存放内容|	0x12|	0x34|	0x56|	0x78

小端： 低字节存储在低地址，高字节存储在高地址

内存地址|	0x4000|	0x4001|	0x4002|	0x4003
-------|---------|-------|-------|-------
存放内容|	0x78|	0x56|	0x34|	0x12

## 置换算法
### 简单的CLOCK置换算法
需要一个**附加位**，也叫**使用位**

主要思想：当某一页装入主存时，将use bit置成1；如果该页之后又被访问到，使用位也还是标记成1。对于页面置换算法，候选的帧集合可以看成是一个循环缓冲区，并且有一个指针和缓冲区相关联。遇到页面替换时，指针指向缓冲区的下一帧。若所有页面的使用位均为1，那么这时候从指针开始循环一个缓冲区，将之前的使用位都清0，并且留在最初的位置上，换出该帧对应的页。若存在使用位为0的元素，则当有新元素要进入时，置换离指针最近的使用位为0的元素。

### 改进型CLOCK置换算法
在之前的CLOCK算法上面除了使用位(used bit)，还增加了一个修改位(modified bit)，有些地方也叫做**脏位**（dirty bit）。现在每一页有两个状态，分别是(使用位，修改位)，可以分以下四种情况：

* (0,0)：最近没有使用使用也没有修改，最佳状态！
* (0,1)：修改过但最近没有使用，将会被写
* (1,0)：使用过但没有被修改，下一轮将再次被用
* (1,1)：使用过也修改过，下一轮页面置换最后的选择

页面替换的顺序：  
从指针当前的位置开始寻找主存中满足(使用位，修改位)为(0,0)的页面；
如果第1步没有找到满足条件的，接着寻找状态为(0,1)页面；
如果依然没有找到，指针回到最初的位置，将集合中所有页面的使用位设置成0。重复第1步，并且如果有必要，重复第2步，这样一定可以找到将要替换的页面。


## IO指令
IO指令实现的数据传送通常发生在**通用寄存器和IO端口之间**，并非IO设备和IO端口



## 文件分配方式
### 连续分配
每个文件在磁盘上占有一组连续的块，其为文件的FCB包含第一块的磁盘地址和连续块的数量
1. 支持顺序访问和直接访问
2. 实现简单、访问文件时需要的寻道数和寻道时间最小，存取速度快
3. 文件长度不宜动态增加
4. 反复增删文件后会产生外部碎片，只适用于长度固定的文件

### 隐式链接分配
每个文件对应一个磁盘块的链表；磁盘块离散分布，除最后一个盘块外，每个盘块都有指向下一个盘块的指针。目录包括文件第一块的指针和最后一块的指针
1. 只能顺序访问文件，如果要访问中间一部分，需要读取所有它之前的磁盘块，效率极其低下
2. 消除了外部碎片，显著地提高了外存空间的利用率
3. 可动态地按需分配盘块，无须事先知道文件的大小
4. 对文件的增删改很方便
5. 稳定性存在问题，一旦断链将导致后续所有文件数据的丢失

### 显示链接分配
把用于链接文件各物理块的指针，显式地存放在内存的一张链接表中。该表在整个磁盘仅设置一张，在每个表项中存放链接指针，即下一个盘块号。在该表中，凡是属于某一文件的第一个盘块号，或者说是每一条链的链首指针所对应的盘块号，均作为文件地址被填入相应的FCB的“物理地址”字段中。由于查找记录的过程是在内存中进行的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。由于分配给文件的所有盘块号都放在该表中，故把该表称为文件分配表**FAT**

### 索引分配
把每个文件的所有的盘块号都集中放在一起构成**索引块（表）**。每个文件都有其索引块，这是一个磁盘块地址的数组。索引块的第i个条目指向文件的第i个块。目录条目包括索引块的地址。
1. 索引分配支持直接访问，且没有外部碎片问题
2. 增加了系统存储空间的开销




## n体交叉编址存储器
即分了n个存储模块，每次访问的模块序号=访存地址%存储器交叉模块数

可能发生访存冲突的规则是：给定的访存地址在相邻的n次访问中出现在同一个存储模块内

## 同步通信 半同步通信 异步通信
同步通信中，系统采用一个统一的时钟信号，不能由各设备自己提供



## 页面置换中的Belady异常
如果对一个进程未分配它所要求的全部页面，有时就会出现分配的页面数增多但缺页率反而提高的异常现象

只可能在FIFO出现



## 带权路径长度（WPL）
所有叶子节点的深度（根节点为0，每往下一层加1），乘以它的权值的和

## C语言static关键字的作用
不加static修饰，函数或者代码块中的变量在函数或者代码块执行完毕后就直接回收销毁了，每次执行都会重新分配内存，每次都会销毁。

加 static 修饰，函数或者代码块中的变量在函数或者代码块执行第一次初始化分配内存后，就算函数或者代码块执行完毕，该变量也不会被回收 销毁，直到程序结束 static 变量才会被回收。

## 生产者消费者问题
信号量
```c
semaphore mutex=1;
semaphore full=0;
semaphore empty=n;
```

生产者
```c
producer(){
   while(1){
      P(empty);
      P(mutex);
      生产
      V(mutex);
      V(full);
   }
}
```

消费者
```c
consumer(){
   while(1){
      P(full);
      P(mutex);
      消费
      V(mutex);
      V(empty);
   }
}
```

## 海明码
设校验位的位数为k，数据位的位数为n，海明码能纠正一位错应满足下列关系：$2^k\geq n+k+1$

## 用于设备和设备控制器（I/O接口）之间互连的接口标准是
USB

## 计算数据所在磁盘的柱面号、磁头号、扇区号的程序是
设备驱动程序

## 索引结点的总数
与单个文件长度无关，代表了文件总数

## 微命令编码
编码方式|直接编码    |字段直接编码
-------|------------|----------
实现方法|微指令的控制字段中每一位都<br>代表一个微命令。设计微指令时，选用或不选用某个微命令，只要将表示该微命令的对应位设置成1或0即可|将微指令的微命令字段分成若干个小字段，把互斥性微命令组合在同意字段中，把相容性微命令组合在不同的字段中，每个字段独立编码，每种编码代表一个微命令且字段编码含义单独定义，与其他字段无关
特点   |简单、直观；指令字长过长，n个微命令就要求微指令的操作字段有n位|微命令字段分段的原则：<br>1）互斥性微命令分在同一段内，相容性微命令分在不同段内<br>2）每个小段中包含的信息位不能太多，否则将增加译码线路的复杂性和译码时间<br>3)一般每个小段还要留出一个状态，表示本字段不发出任何微命令

## I/O接口
I/O接口与CPU之间的I/O总线有数据线、控制线和地址线。控制线和地址线都是单向传输的，从CPU传送给I/O接口，数据线是双向传输的，I/O接口中的**命令字、状态字以及中断类型号**均是由I/O接口发往CPU的，故只能通过I/O总线的数据线传输


## 常见系统调用
类型     |常用UNIX系统调用
---------|--------------
进程控制类|**创建进程fork**：新进程作为调用者的子进程继承了其父进程的环境、已打开的所有文件、根目录和当前目录等<br>**终止进程exit**：父进程将其安排在子进程的末尾。子进程在完成后，进行自我终止<br>**等待子进程结束wait**：wait用于将调用者进程自身挂起，直至其某一子进程终止
文件操纵类|**创建文件creat**：根据用户提供的文件名和许可权方式。创建一个新文件或重写一个已存文件<br>**打开文件open**：根据文件名搜索目录，将目录条目复制到打开文件表，并给用户返回文件描述符fd。文件被打开后，用户堆文件的任何操作都只需使用fd而非路径名<br>**关闭文件close**：断开用户程序与该文件之间已经建立的快捷通路<br>**读文件read和写文件write**：仅当用户利用open打开指定文件后，方可调用read或write对文件执行读或写操作。不使用文件名作为参数

read要求用户提供三个输入参数：1.文件描述符fd；2.buf缓冲区首址；3.传送的字节数n。请求read系统调用会导致CPU从用户态切换到核心态

## 处理机调度
当进程处于临界区时，可以进行处理机调度。比如在使用打印机时
## CPU访存、Cache
只有Cache缺失才需要访存


## 树对应的二叉树中无右孩子的节点个数
所有分支节点最右的子节点无右孩子，根节点也没有右孩子，因此，无右孩子的结点个数=总节点数-叶结点数

## 回路、简单路径
第一个顶点和最后一个顶点相同的路径称为回路

序列中顶点不重复出现的路径称为简单路径

回路显然不是简单路径



## 中断屏蔽技术
在多重中断中，优先级高的中断源有权中断优先级低的中断源

中断屏蔽字的设置，比自己高的优先级置0，表示可以被它们中断，比自己优先级低的或相等的置1，表示不可以被它们中断
## 缺页
缺页中断产生后，需要在内存中找到空闲页框并分配给需要访问的页（可能涉及页面置换），之后缺页中断处理程序调用设备驱动程序做磁盘I/O，将位于外存上的页面调入内存，调入后需要修改页表，将页表中代表该页是否在内存的标志位（或有效位）置为1，并将物理页框号填入相应位置，若必要还需修改其他相关表项等

## 抖动
抖动现象是指刚刚被患处的页很快又要被访问，为此又要换出其他页，而该页又很快被访问，如此频繁地置换页面，已知大部分时间都花在页面置换上，引起系统性能下降。

解决方案：优化页面置换算法；撤销部分进程

## 形成逻辑地址的阶段是
编译

# 计算机网络
## CDMA数据计算
将链路上收到的序列与发送方的码片序列做内积，得到的结果单位化，若为1则代表收到数据1，若为-1则代表数据0
## 广播地址
主机号全1

## 分片
片偏移就是某片在原分组的相对位置，以8个字节为偏移单位。**这就是说，每个分片的长度一定是8字节（64位）的整数倍。**
## 波特率B与数据传输率C的关系
$C=B\log_2N$ N为一个码元所取的离散值个数，即多少相位

## 快速以太网
快速以太网数据帧有效载荷的最小长度为46字节

## ICMP
网络层使用ICMP协议来允许主机或路由器报告差错和异常情况。ICMP报文作为IP层数据报的数据部分，加上数据报的首部，组成IP数据报发送出去

由IP协议直接提供服务

## DHCP
常用于给主机动态地分配IP地址。**DHCP是应用层协议，它是基于UDP的**

## 物理层接口的特性
**机械特性**：定义物理连接的边界点，即插接装置。规定物理连接时所采用的规格、引线的数目、引脚数目和排列情况等

**电气特性**：线路上信号的电压高低、阻抗匹配、传输速率和距离限制等

**功能特性**：指明某条线上出现的某一电平的电压表示何种意义

**过程特性**：指明对于不同功能的各种可能事件的出现顺序

## IP路由器的功能
运行路由协议，设置路由表

监测到拥塞时，合理丢弃IP分组

对收到的IP分组头进行差错校验。**但不保证传输的IP分组不丢失**。这一点从监测到拥塞时的行为也可以看出来

## 报文交换和分组交换
报文交换需要转发设备收到整个报文以后再转发，因此总时间等于两倍的报文传输时间

分组交换收到一个分组就转发，总时间等于（分组数量+1）*单个分组传输时间

## SMTP
只支持传输7bit ASCII码内容

支持在邮件服务器之间发送邮件

支持从用户代理向邮件服务器发送邮件

**不支持从邮件服务器向用户代理发送邮件（POP3）**

## 三种路由协议下层的支持协议
RIP - UDP

OSPF - IP

BGP - TCP

## ARP
若ARP表为空，则主机发出的第一个以太网帧的目的MAC地址为FF-FF-FF-FF

## DHCP
动态分配IP地址

如果电脑还没有分配IP地址，那么在发送分配请求时源IP地址为0.0.0.0，目的IP地址为255.255.255.255，代表广播

## 子网掩码和默认网关设置
如果子网掩码设置正确，则可以访问同一个子网内的主机，即同一台路由器连接的主机。（子网并非局域网，子网是网络层概念，局域网是数据链路层概念）

如果子网掩码和默认网关都设置正确，则可以访问Internet

## 奈奎斯特定理和香农定理
### 奈奎斯特定理
在理想低通信道下的最高码元传输速率的公式：
$$C=2W\log_2N \ (b/s)$$
C是信道容量，W是信道带宽，N是信号状态数

奈奎斯特定理适用的情况是无噪声信道，用来计算理论值，在现实中是不存在的

### 香农定理
在噪声与信号独立的高斯白噪信道中，假设信号的功率为S，噪声功率为N，信道通频带宽为W(Hz)，则该信道的信道容量C有：
$$C=W\log_2(1+\frac{S}{N})\ (b/s)$$

S/N和dB的转换：dB=10lg(S/N)

香农定理计算出的是理论值，现实中会有各种干扰因素，和奈奎斯特定理一样也是达不到的

若题目中说噪声信道的有效率为n，则需要将香农定理定理计算出的结果乘以n
## 802.11数据帧的封装
### IBSS
* 地址1：Destination Address
* 地址2：Source Address
* 地址3：BSSID 
### From AP
* 地址1：Destination Address 
* 地址2：BSSID
* 地址3：Source Address 
### To AP
* 地址1：RA（BSSID） 即AP的IP地址
* 地址2：SA（sourse address）
* 地址3：DA（destination address)
### WDS 
* 地址1：BSSID
* 地址2：Source Address
* 地址3：Destination Address

## RIP,OSPF,BGP运行在那个协议
* RIP运行在UDP
* OSPF运行在IP
* BGP运行在TCP

## TCP连接的建立和释放
SYN表示建立连接

FIN表示关闭连接

ACK表示响应
### 连接建立（三次握手）
第一次：SYN=1，ACK=0（客户端发送）

第二次：SYN=1，ACK=1（服务端发送）

第三次：SYN=0，ACK=1（客户端发送）

### 连接释放（四次握手）
第一次：FIN=1，ACK=0（客户端发送）

第二次：FIN=0，ACK=1（服务端发送，如果服务器端没有数据要传送，则没有第二次）

第三次：FIN=1，ACK=1（服务端发送）

第四次：FIN=0，ACK=1（客户端发送）

## 各种宽带传输介质
100Base-T 双绞线

100Base-Sx 单模光纤

100Base-Fx 多模光纤

## 滑动窗口大小限制
停止等待协议：发送窗口=1，接收窗口=1

后退N步协议：发送窗口>1，接收窗口=1。序号个数>=发送窗口+1，即发送窗口<=序号个数-1即可

选择重传：发送窗口>1，接收窗口>1。  
发送窗口大小+接收窗口大小$\leq 2^n$  （n为位数）
接收窗口大小$\leq$发送窗口大小，接受窗口大小不应超过序号范围的一半即$\leq 2^{(n-1)}$